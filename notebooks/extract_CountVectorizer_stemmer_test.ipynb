{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results: extract_CountVectorizer_stemmer notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload modules every time before executing the Python code typed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import from project root\n",
    "import sys; sys.path.insert(0, '../')\n",
    "\n",
    "import bz2\n",
    "import pickle\n",
    "\n",
    "from access.file_storage import FileStorage\n",
    "from access.interim_storage import InterimStorage\n",
    "from amore.amazon_reviews_reader import AmazonReviewsReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiple usage afterwards\n",
    "\n",
    "file_storage = FileStorage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document-term matrix: (1203682, 918065) <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "with bz2.BZ2File(file_storage.get_filepath('AMORE-CountVec-DocTermMatrix'), 'r') as file:\n",
    "    doc_term_matrix = pickle.loads(file.read())\n",
    "    print('document-term matrix:', doc_term_matrix.shape, type(doc_term_matrix))\n",
    "    # document-term matrix: (1203682, 918065) <class 'scipy.sparse.csr.csr_matrix'>\n",
    "    \n",
    "    # print(doc_term_matrix)\n",
    "    # (0,       816096)  5\n",
    "    # :         :\n",
    "    # (1203681, 686709)  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: 918065 <class 'dict'>\n",
      "example: ('thi', 816096)\n",
      "inv_vocabulary: 918065 <class 'dict'>\n",
      "example: (816096, 'thi')\n"
     ]
    }
   ],
   "source": [
    "with bz2.BZ2File(file_storage.get_filepath('AMORE-CountVec-Vocabulary'), 'r') as file:\n",
    "    vocabulary = pickle.loads(file.read())\n",
    "    print('vocabulary:', len(vocabulary), type(vocabulary))\n",
    "    print('example:', next(iter(vocabulary.items())))\n",
    "    # vocabulary: 918065 <class 'dict'>\n",
    "    # example: thi\n",
    "\n",
    "inv_vocabulary = {v: k for k, v in vocabulary.items()}\n",
    "print('inv_vocabulary:', len(inv_vocabulary), type(inv_vocabulary))\n",
    "print('example:', next(iter(inv_vocabulary.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer ID to review no: 1203682 <class 'dict'>\n",
      "example: (0, 3)\n"
     ]
    }
   ],
   "source": [
    "with bz2.BZ2File(file_storage.get_filepath('AMORE-CountVec-VecidRevno'), 'r') as file:\n",
    "    vecid_revno = pickle.loads(file.read())\n",
    "    print('vectorizer ID to review no:', len(vecid_revno), type(vecid_revno))\n",
    "    print('example:', next(iter(vecid_revno.items())))\n",
    "    # vectorizer ID to review no: 1203682 <class 'dict'>\n",
    "    # example: (0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_docs = 100  # do not load everything (memory usage, time).\n",
    "reader = AmazonReviewsReader(file_storage.get_filepath('amazon_gz_file'), AmazonReviewsReader.MODE_TYPED, max_docs=max_docs)\n",
    "revno_to_text = {}\n",
    "def get_texts(item):\n",
    "    return (item[AmazonReviewsReader.KEY_SUMMARY] + \" \" + item[AmazonReviewsReader.KEY_TEXT]).replace('<br />', ' ')\n",
    "for item in reader:\n",
    "    revno_to_text[item[AmazonReviewsReader.KEY_NUMBER]] = get_texts(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecid: 0   revno: 3   text: This movie needed to be made. The scenes in this film can be very disquieting due to their graphic re-enactment of real events, but this story needs to be told. I will say the violence was injected into the movie with as much taste as manageable when dealing with rape scenes, etc. Inspired by true events, women are being murdered in Juarez after they leave the factory where they work. A fearful community is suddenly given some hope when one of the young victims not only lives, but experiences 'stigmata' after seeing the Virgin Mary.  I was shocked to learn that murders in Juarez are still happening and many are unsolved. I believe this director brought a very important story to the surface. Though it's never pleasant to think about young women being murdered, this movie depicts a harsh reality of the high cost of exploited-cheap labor.  Chrissy K. McVay - Author\n"
     ]
    }
   ],
   "source": [
    "vecid = 0\n",
    "revno = vecid_revno[vecid]\n",
    "text  = revno_to_text[revno]\n",
    "print('vecid:', vecid, '  revno:', revno, '  text:', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi  movi  need  scene  film  veri  disquiet  graphic  reenact  real  event  stori  told  violenc  wa  inject  tast  manag  deal  rape  inspir  true  women  murder  juarez  leav  factori  work  fear  commun  suddenli  given  hope  young  victim  onli  live  experi  stigmata  virgin  mari  shock  learn  happen  mani  unsolv  believ  director  brought  import  surfac  pleasant  think  depict  harsh  realiti  high  cost  exploitedcheap  labor  chrissi  mcvay  author  "
     ]
    }
   ],
   "source": [
    "for dim_value in doc_term_matrix[vecid].nonzero()[1]:\n",
    "    print(inv_vocabulary[dim_value], end='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie        not included\n",
    "# disquieting\n",
    "\n",
    "# thi     why included? 'this'?\n",
    "# inspir                'Inspired'?\n",
    "# tast                  'taste'?\n",
    "# leav                  'leave'?\n",
    "# onli                  ?\n",
    "\n",
    "# exploited-cheap -> exploitedcheap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens if len(item)>=3]\n",
    "\n",
    "import string\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "from nltk import word_tokenize\n",
    "def normalize(text):\n",
    "    return stem_tokens(word_tokenize(text.lower().translate(remove_punctuation_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie needed to be made. The scenes in this film can be very disquieting due to their graphic re-enactment of real events, but this story needs to be told. I will say the violence was injected into the movie with as much taste as manageable when dealing with rape scenes, etc. Inspired by true events, women are being murdered in Juarez after they leave the factory where they work. A fearful community is suddenly given some hope when one of the young victims not only lives, but experiences 'stigmata' after seeing the Virgin Mary.  I was shocked to learn that murders in Juarez are still happening and many are unsolved. I believe this director brought a very important story to the surface. Though it's never pleasant to think about young women being murdered, this movie depicts a harsh reality of the high cost of exploited-cheap labor.  Chrissy K. McVay - Author\n",
      "\n",
      "['thi', 'movi', 'need', 'made', 'the', 'scene', 'thi', 'film', 'can', 'veri', 'disquiet', 'due', 'their', 'graphic', 'reenact', 'real', 'event', 'but', 'thi', 'stori', 'need', 'told', 'will', 'say', 'the', 'violenc', 'wa', 'inject', 'into', 'the', 'movi', 'with', 'much', 'tast', 'manag', 'when', 'deal', 'with', 'rape', 'scene', 'etc', 'inspir', 'true', 'event', 'women', 'are', 'be', 'murder', 'juarez', 'after', 'they', 'leav', 'the', 'factori', 'where', 'they', 'work', 'fear', 'commun', 'suddenli', 'given', 'some', 'hope', 'when', 'one', 'the', 'young', 'victim', 'not', 'onli', 'live', 'but', 'experi', 'stigmata', 'after', 'see', 'the', 'virgin', 'mari', 'wa', 'shock', 'learn', 'that', 'murder', 'juarez', 'are', 'still', 'happen', 'and', 'mani', 'are', 'unsolv', 'believ', 'thi', 'director', 'brought', 'veri', 'import', 'stori', 'the', 'surfac', 'though', 'it', 'never', 'pleasant', 'think', 'about', 'young', 'women', 'be', 'murder', 'thi', 'movi', 'depict', 'harsh', 'realiti', 'the', 'high', 'cost', 'exploitedcheap', 'labor', 'chrissi', 'mcvay', 'author']\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print()\n",
    "print(normalize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{33: None, 34: None, 35: None, 36: None, 37: None, 38: None, 39: None, 40: None, 41: None, 42: None, 43: None, 44: None, 45: None, 46: None, 47: None, 58: None, 59: None, 60: None, 61: None, 62: None, 63: None, 64: None, 91: None, 92: None, 93: None, 94: None, 95: None, 96: None, 123: None, 124: None, 125: None, 126: None}\n",
      "\n",
      "!  \"  #  $  %  &  '  (  )  *  +  ,  -  .  /  :  ;  <  =  >  ?  @  [  \\  ]  ^  _  `  {  |  }  ~  "
     ]
    }
   ],
   "source": [
    "print(remove_punctuation_map)\n",
    "print()\n",
    "for char in string.punctuation:\n",
    "    print(char, end='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include words with len < 3\n",
    "\n",
    "def stem_tokens2(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "def normalize2(text):\n",
    "    return stem_tokens2(word_tokenize(text.lower().translate(remove_punctuation_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'movi', 'need', 'to', 'be', 'made', 'the', 'scene', 'in', 'thi', 'film', 'can', 'be', 'veri', 'disquiet', 'due', 'to', 'their', 'graphic', 'reenact', 'of', 'real', 'event', 'but', 'thi', 'stori', 'need', 'to', 'be', 'told', 'i', 'will', 'say', 'the', 'violenc', 'wa', 'inject', 'into', 'the', 'movi', 'with', 'as', 'much', 'tast', 'as', 'manag', 'when', 'deal', 'with', 'rape', 'scene', 'etc', 'inspir', 'by', 'true', 'event', 'women', 'are', 'be', 'murder', 'in', 'juarez', 'after', 'they', 'leav', 'the', 'factori', 'where', 'they', 'work', 'a', 'fear', 'commun', 'is', 'suddenli', 'given', 'some', 'hope', 'when', 'one', 'of', 'the', 'young', 'victim', 'not', 'onli', 'live', 'but', 'experi', 'stigmata', 'after', 'see', 'the', 'virgin', 'mari', 'i', 'wa', 'shock', 'to', 'learn', 'that', 'murder', 'in', 'juarez', 'are', 'still', 'happen', 'and', 'mani', 'are', 'unsolv', 'i', 'believ', 'thi', 'director', 'brought', 'a', 'veri', 'import', 'stori', 'to', 'the', 'surfac', 'though', 'it', 'never', 'pleasant', 'to', 'think', 'about', 'young', 'women', 'be', 'murder', 'thi', 'movi', 'depict', 'a', 'harsh', 'realiti', 'of', 'the', 'high', 'cost', 'of', 'exploitedcheap', 'labor', 'chrissi', 'k', 'mcvay', 'author']\n"
     ]
    }
   ],
   "source": [
    "print(normalize2(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plus: no translate\n",
    "\n",
    "def stem_tokens3(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "def normalize3(text):\n",
    "    return stem_tokens3(word_tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'movi', 'need', 'to', 'be', 'made', '.', 'the', 'scene', 'in', 'thi', 'film', 'can', 'be', 'veri', 'disquiet', 'due', 'to', 'their', 'graphic', 're-enact', 'of', 'real', 'event', ',', 'but', 'thi', 'stori', 'need', 'to', 'be', 'told', '.', 'i', 'will', 'say', 'the', 'violenc', 'wa', 'inject', 'into', 'the', 'movi', 'with', 'as', 'much', 'tast', 'as', 'manag', 'when', 'deal', 'with', 'rape', 'scene', ',', 'etc', '.', 'inspir', 'by', 'true', 'event', ',', 'women', 'are', 'be', 'murder', 'in', 'juarez', 'after', 'they', 'leav', 'the', 'factori', 'where', 'they', 'work', '.', 'a', 'fear', 'commun', 'is', 'suddenli', 'given', 'some', 'hope', 'when', 'one', 'of', 'the', 'young', 'victim', 'not', 'onli', 'live', ',', 'but', 'experi', \"'stigmata\", \"'\", 'after', 'see', 'the', 'virgin', 'mari', '.', 'i', 'wa', 'shock', 'to', 'learn', 'that', 'murder', 'in', 'juarez', 'are', 'still', 'happen', 'and', 'mani', 'are', 'unsolv', '.', 'i', 'believ', 'thi', 'director', 'brought', 'a', 'veri', 'import', 'stori', 'to', 'the', 'surfac', '.', 'though', 'it', \"'s\", 'never', 'pleasant', 'to', 'think', 'about', 'young', 'women', 'be', 'murder', ',', 'thi', 'movi', 'depict', 'a', 'harsh', 'realiti', 'of', 'the', 'high', 'cost', 'of', 'exploited-cheap', 'labor', '.', 'chrissi', 'k.', 'mcvay', '-', 'author']\n"
     ]
    }
   ],
   "source": [
    "print(normalize3(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plus: no stemmer\n",
    "\n",
    "def normalize4(text):\n",
    "    return word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'needed', 'to', 'be', 'made', '.', 'the', 'scenes', 'in', 'this', 'film', 'can', 'be', 'very', 'disquieting', 'due', 'to', 'their', 'graphic', 're-enactment', 'of', 'real', 'events', ',', 'but', 'this', 'story', 'needs', 'to', 'be', 'told', '.', 'i', 'will', 'say', 'the', 'violence', 'was', 'injected', 'into', 'the', 'movie', 'with', 'as', 'much', 'taste', 'as', 'manageable', 'when', 'dealing', 'with', 'rape', 'scenes', ',', 'etc', '.', 'inspired', 'by', 'true', 'events', ',', 'women', 'are', 'being', 'murdered', 'in', 'juarez', 'after', 'they', 'leave', 'the', 'factory', 'where', 'they', 'work', '.', 'a', 'fearful', 'community', 'is', 'suddenly', 'given', 'some', 'hope', 'when', 'one', 'of', 'the', 'young', 'victims', 'not', 'only', 'lives', ',', 'but', 'experiences', \"'stigmata\", \"'\", 'after', 'seeing', 'the', 'virgin', 'mary', '.', 'i', 'was', 'shocked', 'to', 'learn', 'that', 'murders', 'in', 'juarez', 'are', 'still', 'happening', 'and', 'many', 'are', 'unsolved', '.', 'i', 'believe', 'this', 'director', 'brought', 'a', 'very', 'important', 'story', 'to', 'the', 'surface', '.', 'though', 'it', \"'s\", 'never', 'pleasant', 'to', 'think', 'about', 'young', 'women', 'being', 'murdered', ',', 'this', 'movie', 'depicts', 'a', 'harsh', 'reality', 'of', 'the', 'high', 'cost', 'of', 'exploited-cheap', 'labor', '.', 'chrissy', 'k.', 'mcvay', '-', 'author']\n"
     ]
    }
   ],
   "source": [
    "print(normalize4(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only no stemmer / substitute with whitespace instead of removind punctuation -> good result\n",
    "\n",
    "def stem_tokens5(tokens):\n",
    "    return [item for item in tokens if len(item)>=3]\n",
    "\n",
    "remove_punctuation_map = dict((ord(char), ' ') for char in string.punctuation)\n",
    "\n",
    "def normalize5(text):\n",
    "    return stem_tokens5(word_tokenize(text.lower().translate(remove_punctuation_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'needed', 'made', 'the', 'scenes', 'this', 'film', 'can', 'very', 'disquieting', 'due', 'their', 'graphic', 'enactment', 'real', 'events', 'but', 'this', 'story', 'needs', 'told', 'will', 'say', 'the', 'violence', 'was', 'injected', 'into', 'the', 'movie', 'with', 'much', 'taste', 'manageable', 'when', 'dealing', 'with', 'rape', 'scenes', 'etc', 'inspired', 'true', 'events', 'women', 'are', 'being', 'murdered', 'juarez', 'after', 'they', 'leave', 'the', 'factory', 'where', 'they', 'work', 'fearful', 'community', 'suddenly', 'given', 'some', 'hope', 'when', 'one', 'the', 'young', 'victims', 'not', 'only', 'lives', 'but', 'experiences', 'stigmata', 'after', 'seeing', 'the', 'virgin', 'mary', 'was', 'shocked', 'learn', 'that', 'murders', 'juarez', 'are', 'still', 'happening', 'and', 'many', 'are', 'unsolved', 'believe', 'this', 'director', 'brought', 'very', 'important', 'story', 'the', 'surface', 'though', 'never', 'pleasant', 'think', 'about', 'young', 'women', 'being', 'murdered', 'this', 'movie', 'depicts', 'harsh', 'reality', 'the', 'high', 'cost', 'exploited', 'cheap', 'labor', 'chrissy', 'mcvay', 'author']\n"
     ]
    }
   ],
   "source": [
    "print(normalize5(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EML4U)",
   "language": "python",
   "name": "eml4u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
